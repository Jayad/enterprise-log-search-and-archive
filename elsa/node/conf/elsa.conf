{
	# Local mysql database connection info
	"database" : { 
		"db": "syslog",
		"data_db": "syslog_data",
		"dsn" : "dbi:mysql:database=syslog", 
		"username" : "elsa", 
		"password" : "biglog" 
	},
	# Trivial directories where the system will coordinate locks.  Default should always be fine unless you change from "/usr/local/elsa"
	"lockfile_dir": "/usr/local/elsa/node/tmp/locks",
	# Tuning for number of indexes the system will handle.  There are temporary indexes which are (by default) 60 second batch-loaded indexes which get consolidated when the total number of logs in temporary indexes is over the setting for "perm_index_size."  By default, ELSA will consolidate its temporary indexes when it hits 10 million or temporary indexes are more than 40% of 200 (80).  If 200 permanent indexes are used before it hits the log size capacity, then it will prematurely overwrite permanent indexes.  Therefore, if you do not collect 10 million logs in less than 200 minutes, you will lose logs because they are overwritten prematurely.  So, if your logging rate is less than 833.3 logs per second, you will want to increase the number of indexes.
	"num_indexes": 200,
	# If you want to archive logs in addition to indexing them, leave this and/or edit the numbers.  Set percentage to 0 if you do not want to archive.
	"archive": {
		# Uncomment to establish a retention period in days for archive logs
		#"days": 90,
		"percentage": 33,
		"table_size": 10000000,
	},
	# Size limit in bytes for logs + index size.  Set this to be 90-95% of your total data disk space.
	# Size can also be specified as a percentage if the percent sign is included at the end (e.g. 95%).
	"log_size_limit" : 200000000000,
	# Size limit in bytes for logs + index size of imported logs. Optional, defaults to 50% of log_size_limit.
	#"import_log_size_limit": 10000000,
	"sphinx" : {
		# Uncomment to establish a retention period in days for indexed logs
		#"days": 14,
		# location for sphinx indexer, should not need to change unless you installed to a non-standard location
		"indexer": "/usr/local/sphinx/bin/indexer",
		# emergency consolidation will be done if too many temp indexes pile up
		"allowed_temp_percent" : 40,
		# Check to be sure that temporary indexes (which use a lot of RAM) never go above this amount of RAM, or they will be prematurely consolidated.
		"allowed_mem_percent": 25,
		# Host/port sphinx runs on.  Default should be fine.
		"host" : "127.0.0.1",
		"port" : 9312,
		"mysql_port": 9306,
		# The actual config file sphinx will use, should not need to change unless you are installing to non-standard locations.
		"config_file" : "/usr/local/etc/sphinx.conf",
		# Data directory for storing indexes.  Place on your biggest storage.
		"index_path" : "/data/sphinx",
		# This is the size of the temporary index batches.  You should probably leave as the default, but you can increase for fewer temp indexes, especially if you have low log volume.  The higher the value here, the longer it will take for new logs to be available to queries.
		"index_interval" : 60,
		# Setting for how many temp logs should be allowed before being consolidated.  This value should be fine for systems with more than 833 logs/second.
		"perm_index_size" : 10000000,
		# Where the optional stopwords file is
		"stopwords": {
			"file": "/usr/local/etc/sphinx_stopwords.txt",
			"top_n": 0,
			"interval": 0,
			"whitelist": []
		},
		"pid_file": "/var/run/searchd.pid"
	},
	# Uncomment to enable realtime indexes (for low log volumes, such as less than 1000 events/sec)
	#"realtime": {
		# How many messages to receive before inserting. This is an important setting: too low and you will get bad throughput, 
		#  too high and it will take up to sphinx{index_interval} for logs to appear, just like non-realtime mode.
		#"batch_limit": 10,
		# What is our threshold for entering batch loading? Rates lower than this rate will use realtime.
		#"rate": 1000
	#},
	# Uncomment to enable forwarding
	#"forwarding": {
	#	"forward_only": 1, # set to zero to both forward and index/archive
	#	"destinations": [
	#		{ "method": "cp", "dir": "/mnt/nfs/central_server" },
	# Example with password
	#		{ "method": "scp", "user": "user", "password": "password", "port": 8022, "host": "central.elsa.local", "dir": "/data/elsa/tmp/buffers" },
	# Example using key
	#		{ "method": "scp", "key_path": "/root/.ssh/id_rsa.pub", "host": "central.elsa.local", "dir": "/data/elsa/tmp/buffers" }
	# Example using URL forwarding
	#		{ "method": "url", "url": "https://example.com/API/upload", "verify_mode": 0 }
	# Example for an ops log server (logs about ELSA operations for sending multiple ELSA node logs to, not the logs ELSA indexes)
	#		{ "ops": 1, "method": "url", "https://opslogs.example.com/API/upload", "verify_mode": 1 }
	#	]
	#},
	# Where to place the ELSA management logs (not the logs we are receiving)
	"logdir" : "/data/elsa/log",
	"mysql_dir": "/data/elsa/mysql",
	# How many concurrent log readers can run. 1 should be fine for up to 50k logs/sec on the same node.
	"num_log_readers" : 1,
	# Logging level management logs (does not affect logs received).
	"debug_level" : "TRACE",
	# Where to store the incoming logs before being loaded and processed.  You can set to /dev/shm on Linux for faster loading, but shouldn't be necessary.
	"buffer_dir" : "/data/elsa/tmp/buffers",
	# Log any parsing errors?  This can be very verbose initially, but needed to tell if there are some subtle parsing problems.
	"log_parse_errors": 1,
	# Stats retention settings
	"stats" : {
		"retention_days": 365
	},
	# Minimum number of hosts we expect to get logs from, currently only used to record a warning message in the log if we don't get this many
	"min_expected_hosts": 2
}